{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data\n",
    "`L0~gs.`api`.log.57_13-09-2019_06:59 34703 INFO gs.`openstack.wsgi.server `[ req-y9mjwk-n1yj-6wl35r-nhwlbg ] `HTTP exception thrown: No entry found for any event\n",
    "\n",
    "The `highlighted` text does not provide intuition about the log hence should be removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code inputs the given log file and outputs a clean file (\"new.txt\") with important features\n",
    "## Input\n",
    "`L0~gs.`api`.log.57_13-09-2019_06:59 34703 INFO gs.`openstack.wsgi.server `[ req-y9mjwk-n1yj-6wl35r-nhwlbg ] `HTTP exception thrown: No entry found for any event\n",
    "\n",
    "## output\n",
    "_**api , openstack wsgi server ,  HTTP exception thrown  No entry found for any event**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "log=[]\n",
    "f_new= open(\"new2.txt\",'w')\n",
    "with open(\"private_test_set.txt\") as f:\n",
    "    for line in f:\n",
    "        idx=line.find(\"~gs\")\n",
    "        if idx!=-1:\n",
    "            new=line[idx+4:]\n",
    "        idx1=new.find(\".log\")\n",
    "        idx2=new.find(\"INFO\")\n",
    "        if idx1!=-1 and idx2!=-1:\n",
    "            new=new[:idx1]+\" \"+new[idx2+8:]\n",
    "        new=new.replace(\"] [\",\"*\")\n",
    "        idx1=new.find(\"[\")\n",
    "        idx2=new.find(\"]\")\n",
    "        if idx1!=-1 and idx2!=-1:\n",
    "            new=new[:idx1]+\" \"+new[idx2+1:]\n",
    "        idx=new.find(\"status:\")\n",
    "        if idx!=-1:\n",
    "            new=new[:idx]\n",
    "        new = re.sub('[^a-zA-Z \\n\\ ]', ' ', new)\n",
    "        print(new , file=f_new)\n",
    "        \n",
    "f_new.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "the useful words will act as features of log\n",
    "`features` is a list of useful word (space seperated string) in log\n",
    "\n",
    "features[i] denotes ith line of log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "with open(\"new2.txt\",\"r\") as f:  # opening the saved file\n",
    "    for i in f:\n",
    "        if i!=\"\\n\":\n",
    "            features+=[\" \".join(i.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vecterization\n",
    "as computer only understands numbers,so we will convert words to integers\n",
    "makes one hot encoding of words in ith string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_ = vectorizer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "print((len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimention Reduction\n",
    "as we have extra features which dont contribute in classification we will decrease its dimentions to 10.\n",
    "\n",
    "Here we will use **autoencoder** to decrease dimentionality\n",
    "## AutoEncoder\n",
    "An autoencoder is a neural network that learns to copy its input to its output. It has an internal (hidden) layer that describes a code used to represent the input, and it is constituted by two main parts: an encoder that maps the input into the code, and a decoder that maps the code to a reconstruction of the original input.\n",
    "\n",
    "This is why usually autoencoders are restricted in ways that force them to reconstruct the input only approximately, prioritizing the most relevant aspects of the data to be copied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk/Dev/machine_learning/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['time', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import keras\n",
    "import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "from time import time\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "# from scipy.misc import imread\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our input placeholder\n",
    "input_ = Input(shape=((len(vectorizer.get_feature_names())),))\n",
    "\n",
    "encoded = Dense(10, activation='sigmoid')(input_)\n",
    "\n",
    "decoded = Dense((len(vectorizer.get_feature_names())))(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 686)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 10)                6870      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 686)               7546      \n",
      "=================================================================\n",
      "Total params: 14,416\n",
      "Trainable params: 14,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here epoch and batch size are calculated on the basis of trail and error method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1050/1050 [==============================] - 0s 75us/step - loss: 0.0270\n",
      "Epoch 2/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0254\n",
      "Epoch 3/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0239\n",
      "Epoch 4/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0227\n",
      "Epoch 5/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0216\n",
      "Epoch 6/500\n",
      "1050/1050 [==============================] - 0s 21us/step - loss: 0.0208\n",
      "Epoch 7/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0201\n",
      "Epoch 8/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0195\n",
      "Epoch 9/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0190\n",
      "Epoch 10/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0186\n",
      "Epoch 11/500\n",
      "1050/1050 [==============================] - 0s 24us/step - loss: 0.0183\n",
      "Epoch 12/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0180\n",
      "Epoch 13/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0178\n",
      "Epoch 14/500\n",
      "1050/1050 [==============================] - 0s 25us/step - loss: 0.0176\n",
      "Epoch 15/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0174\n",
      "Epoch 16/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0173\n",
      "Epoch 17/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0171\n",
      "Epoch 18/500\n",
      "1050/1050 [==============================] - 0s 21us/step - loss: 0.0170\n",
      "Epoch 19/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0169\n",
      "Epoch 20/500\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.016 - 0s 28us/step - loss: 0.0167\n",
      "Epoch 21/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0166\n",
      "Epoch 22/500\n",
      "1050/1050 [==============================] - 0s 24us/step - loss: 0.0165\n",
      "Epoch 23/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0164\n",
      "Epoch 24/500\n",
      "1050/1050 [==============================] - 0s 23us/step - loss: 0.0164\n",
      "Epoch 25/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0163\n",
      "Epoch 26/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0162\n",
      "Epoch 27/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0161\n",
      "Epoch 28/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0161\n",
      "Epoch 29/500\n",
      "1050/1050 [==============================] - 0s 31us/step - loss: 0.0160\n",
      "Epoch 30/500\n",
      "1050/1050 [==============================] - 0s 28us/step - loss: 0.0159\n",
      "Epoch 31/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0159\n",
      "Epoch 32/500\n",
      "1050/1050 [==============================] - 0s 23us/step - loss: 0.0158\n",
      "Epoch 33/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0158\n",
      "Epoch 34/500\n",
      "1050/1050 [==============================] - 0s 27us/step - loss: 0.0157\n",
      "Epoch 35/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0156\n",
      "Epoch 36/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0156\n",
      "Epoch 37/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0155\n",
      "Epoch 38/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0155\n",
      "Epoch 39/500\n",
      "1050/1050 [==============================] - 0s 23us/step - loss: 0.0155\n",
      "Epoch 40/500\n",
      "1050/1050 [==============================] - 0s 25us/step - loss: 0.0154\n",
      "Epoch 41/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0154\n",
      "Epoch 42/500\n",
      "1050/1050 [==============================] - 0s 21us/step - loss: 0.0153\n",
      "Epoch 43/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0153\n",
      "Epoch 44/500\n",
      "1050/1050 [==============================] - 0s 24us/step - loss: 0.0153\n",
      "Epoch 45/500\n",
      "1050/1050 [==============================] - 0s 23us/step - loss: 0.0152\n",
      "Epoch 46/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0152\n",
      "Epoch 47/500\n",
      "1050/1050 [==============================] - 0s 24us/step - loss: 0.0151\n",
      "Epoch 48/500\n",
      "1050/1050 [==============================] - 0s 30us/step - loss: 0.0151\n",
      "Epoch 49/500\n",
      "1050/1050 [==============================] - 0s 27us/step - loss: 0.0151\n",
      "Epoch 50/500\n",
      "1050/1050 [==============================] - 0s 25us/step - loss: 0.0150\n",
      "Epoch 51/500\n",
      "1050/1050 [==============================] - 0s 25us/step - loss: 0.0150\n",
      "Epoch 52/500\n",
      "1050/1050 [==============================] - 0s 27us/step - loss: 0.0150\n",
      "Epoch 53/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0149\n",
      "Epoch 54/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0149\n",
      "Epoch 55/500\n",
      "1050/1050 [==============================] - 0s 24us/step - loss: 0.0149\n",
      "Epoch 56/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0148\n",
      "Epoch 57/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0148\n",
      "Epoch 58/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0148\n",
      "Epoch 59/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0147\n",
      "Epoch 60/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0147\n",
      "Epoch 61/500\n",
      "1050/1050 [==============================] - 0s 23us/step - loss: 0.0147\n",
      "Epoch 62/500\n",
      "1050/1050 [==============================] - 0s 21us/step - loss: 0.0147\n",
      "Epoch 63/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0146\n",
      "Epoch 64/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0146\n",
      "Epoch 65/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0146\n",
      "Epoch 66/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0145\n",
      "Epoch 67/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0145\n",
      "Epoch 68/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0145\n",
      "Epoch 69/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0145\n",
      "Epoch 70/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0144\n",
      "Epoch 71/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0144\n",
      "Epoch 72/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0144\n",
      "Epoch 73/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0144\n",
      "Epoch 74/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0143\n",
      "Epoch 75/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0143\n",
      "Epoch 76/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0143\n",
      "Epoch 77/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0142\n",
      "Epoch 78/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0142\n",
      "Epoch 79/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0142\n",
      "Epoch 80/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0142\n",
      "Epoch 81/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0141\n",
      "Epoch 82/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0141\n",
      "Epoch 83/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0141\n",
      "Epoch 84/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0141\n",
      "Epoch 85/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0140\n",
      "Epoch 86/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0140\n",
      "Epoch 87/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0140\n",
      "Epoch 88/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0139\n",
      "Epoch 89/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0139\n",
      "Epoch 90/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0139\n",
      "Epoch 91/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0139\n",
      "Epoch 92/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0138\n",
      "Epoch 93/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0138\n",
      "Epoch 94/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0138\n",
      "Epoch 95/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0137\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 23us/step - loss: 0.0137\n",
      "Epoch 97/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0137\n",
      "Epoch 98/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0137\n",
      "Epoch 99/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0136\n",
      "Epoch 100/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0136\n",
      "Epoch 101/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0136\n",
      "Epoch 102/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0135\n",
      "Epoch 103/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0135\n",
      "Epoch 104/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0135\n",
      "Epoch 105/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0134\n",
      "Epoch 106/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0134\n",
      "Epoch 107/500\n",
      "1050/1050 [==============================] - 0s 21us/step - loss: 0.0134\n",
      "Epoch 108/500\n",
      "1050/1050 [==============================] - 0s 21us/step - loss: 0.0133\n",
      "Epoch 109/500\n",
      "1050/1050 [==============================] - 0s 26us/step - loss: 0.0133\n",
      "Epoch 110/500\n",
      "1050/1050 [==============================] - 0s 24us/step - loss: 0.0133\n",
      "Epoch 111/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0132\n",
      "Epoch 112/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0132\n",
      "Epoch 113/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0132\n",
      "Epoch 114/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0131\n",
      "Epoch 115/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0131\n",
      "Epoch 116/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0131\n",
      "Epoch 117/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0130\n",
      "Epoch 118/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0130\n",
      "Epoch 119/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0130\n",
      "Epoch 120/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0129\n",
      "Epoch 121/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0129\n",
      "Epoch 122/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0129\n",
      "Epoch 123/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0128\n",
      "Epoch 124/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0128\n",
      "Epoch 125/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0128\n",
      "Epoch 126/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0127\n",
      "Epoch 127/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0127\n",
      "Epoch 128/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0127\n",
      "Epoch 129/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0126\n",
      "Epoch 130/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0126\n",
      "Epoch 131/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0126\n",
      "Epoch 132/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0125\n",
      "Epoch 133/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0125\n",
      "Epoch 134/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0125\n",
      "Epoch 135/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0124\n",
      "Epoch 136/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0124\n",
      "Epoch 137/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0124\n",
      "Epoch 138/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0123\n",
      "Epoch 139/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0123\n",
      "Epoch 140/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0123\n",
      "Epoch 141/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0122\n",
      "Epoch 142/500\n",
      "1050/1050 [==============================] - 0s 12us/step - loss: 0.0122\n",
      "Epoch 143/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0122\n",
      "Epoch 144/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0121\n",
      "Epoch 145/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0121\n",
      "Epoch 146/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0121\n",
      "Epoch 147/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0120\n",
      "Epoch 148/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0120\n",
      "Epoch 149/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0120\n",
      "Epoch 150/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0119\n",
      "Epoch 151/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0119\n",
      "Epoch 152/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0119\n",
      "Epoch 153/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0119\n",
      "Epoch 154/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0118\n",
      "Epoch 155/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0118\n",
      "Epoch 156/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0118\n",
      "Epoch 157/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0117\n",
      "Epoch 158/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0117\n",
      "Epoch 159/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0117\n",
      "Epoch 160/500\n",
      "1050/1050 [==============================] - 0s 12us/step - loss: 0.0116\n",
      "Epoch 161/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0116\n",
      "Epoch 162/500\n",
      "1050/1050 [==============================] - 0s 12us/step - loss: 0.0116\n",
      "Epoch 163/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0115\n",
      "Epoch 164/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0115\n",
      "Epoch 165/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0115\n",
      "Epoch 166/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0115\n",
      "Epoch 167/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0114\n",
      "Epoch 168/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0114\n",
      "Epoch 169/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0114\n",
      "Epoch 170/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0113\n",
      "Epoch 171/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0113\n",
      "Epoch 172/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0113\n",
      "Epoch 173/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0113\n",
      "Epoch 174/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0112\n",
      "Epoch 175/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0112\n",
      "Epoch 176/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0112\n",
      "Epoch 177/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0111\n",
      "Epoch 178/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0111\n",
      "Epoch 179/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0111\n",
      "Epoch 180/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0111\n",
      "Epoch 181/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0110\n",
      "Epoch 182/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0110\n",
      "Epoch 183/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0110\n",
      "Epoch 184/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0109\n",
      "Epoch 185/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0109\n",
      "Epoch 186/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0109\n",
      "Epoch 187/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0109\n",
      "Epoch 188/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0108\n",
      "Epoch 189/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0108\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0108\n",
      "Epoch 191/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0107\n",
      "Epoch 192/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0107\n",
      "Epoch 193/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0107\n",
      "Epoch 194/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0107\n",
      "Epoch 195/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0106\n",
      "Epoch 196/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0106\n",
      "Epoch 197/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0106\n",
      "Epoch 198/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0106\n",
      "Epoch 199/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0105\n",
      "Epoch 200/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0105\n",
      "Epoch 201/500\n",
      "1050/1050 [==============================] - 0s 12us/step - loss: 0.0105\n",
      "Epoch 202/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0104\n",
      "Epoch 203/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0104\n",
      "Epoch 204/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0104\n",
      "Epoch 205/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0104\n",
      "Epoch 206/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0103\n",
      "Epoch 207/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0103\n",
      "Epoch 208/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0103\n",
      "Epoch 209/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0102\n",
      "Epoch 210/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0102\n",
      "Epoch 211/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0102\n",
      "Epoch 212/500\n",
      "1050/1050 [==============================] - 0s 11us/step - loss: 0.0102\n",
      "Epoch 213/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0101\n",
      "Epoch 214/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0101\n",
      "Epoch 215/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0101\n",
      "Epoch 216/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0101\n",
      "Epoch 217/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0100\n",
      "Epoch 218/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0100\n",
      "Epoch 219/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0100\n",
      "Epoch 220/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0100\n",
      "Epoch 221/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0099\n",
      "Epoch 222/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0099\n",
      "Epoch 223/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0099\n",
      "Epoch 224/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0099\n",
      "Epoch 225/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0098\n",
      "Epoch 226/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0098\n",
      "Epoch 227/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0098\n",
      "Epoch 228/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0098\n",
      "Epoch 229/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0097\n",
      "Epoch 230/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0097\n",
      "Epoch 231/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0097\n",
      "Epoch 232/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0097\n",
      "Epoch 233/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0097\n",
      "Epoch 234/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0096\n",
      "Epoch 235/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0096\n",
      "Epoch 236/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0096\n",
      "Epoch 237/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0096\n",
      "Epoch 238/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0096\n",
      "Epoch 239/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0095\n",
      "Epoch 240/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0095\n",
      "Epoch 241/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0095\n",
      "Epoch 242/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0095\n",
      "Epoch 243/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0095\n",
      "Epoch 244/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0094\n",
      "Epoch 245/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0094\n",
      "Epoch 246/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0094\n",
      "Epoch 247/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0094\n",
      "Epoch 248/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0094\n",
      "Epoch 249/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0093\n",
      "Epoch 250/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0093\n",
      "Epoch 251/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0093\n",
      "Epoch 252/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0093\n",
      "Epoch 253/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0093\n",
      "Epoch 254/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0092\n",
      "Epoch 255/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0092\n",
      "Epoch 256/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0092\n",
      "Epoch 257/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0092\n",
      "Epoch 258/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0092\n",
      "Epoch 259/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0092\n",
      "Epoch 260/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0091\n",
      "Epoch 261/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0091\n",
      "Epoch 262/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0091\n",
      "Epoch 263/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0091\n",
      "Epoch 264/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0091\n",
      "Epoch 265/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0091\n",
      "Epoch 266/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0090\n",
      "Epoch 267/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0090\n",
      "Epoch 268/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0090\n",
      "Epoch 269/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0090\n",
      "Epoch 270/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0090\n",
      "Epoch 271/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0090\n",
      "Epoch 272/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0089\n",
      "Epoch 273/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0089\n",
      "Epoch 274/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0089\n",
      "Epoch 275/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0089\n",
      "Epoch 276/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0089\n",
      "Epoch 277/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0089\n",
      "Epoch 278/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0088\n",
      "Epoch 279/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0088\n",
      "Epoch 280/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0088\n",
      "Epoch 281/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0088\n",
      "Epoch 282/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0088\n",
      "Epoch 283/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0088\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0088\n",
      "Epoch 285/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0087\n",
      "Epoch 286/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0087\n",
      "Epoch 287/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0087\n",
      "Epoch 288/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0087\n",
      "Epoch 289/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0087\n",
      "Epoch 290/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0087\n",
      "Epoch 291/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0087\n",
      "Epoch 292/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0086\n",
      "Epoch 293/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0086\n",
      "Epoch 294/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0086\n",
      "Epoch 295/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0086\n",
      "Epoch 296/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0086\n",
      "Epoch 297/500\n",
      "1050/1050 [==============================] - 0s 12us/step - loss: 0.0086\n",
      "Epoch 298/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0086\n",
      "Epoch 299/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0085\n",
      "Epoch 300/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0085\n",
      "Epoch 301/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0085\n",
      "Epoch 302/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0085\n",
      "Epoch 303/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0085\n",
      "Epoch 304/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0085\n",
      "Epoch 305/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0085\n",
      "Epoch 306/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0084\n",
      "Epoch 307/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0084\n",
      "Epoch 308/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0084\n",
      "Epoch 309/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0084\n",
      "Epoch 310/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0084\n",
      "Epoch 311/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0084\n",
      "Epoch 312/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0084\n",
      "Epoch 313/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0084\n",
      "Epoch 314/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0083\n",
      "Epoch 315/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0083\n",
      "Epoch 316/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0083\n",
      "Epoch 317/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0083\n",
      "Epoch 318/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0083\n",
      "Epoch 319/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0083\n",
      "Epoch 320/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0083\n",
      "Epoch 321/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0083\n",
      "Epoch 322/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0082\n",
      "Epoch 323/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0082\n",
      "Epoch 324/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0082\n",
      "Epoch 325/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0082\n",
      "Epoch 326/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0082\n",
      "Epoch 327/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0082\n",
      "Epoch 328/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0082\n",
      "Epoch 329/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0082\n",
      "Epoch 330/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0081\n",
      "Epoch 331/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0081\n",
      "Epoch 332/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0081\n",
      "Epoch 333/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0081\n",
      "Epoch 334/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0081\n",
      "Epoch 335/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0081\n",
      "Epoch 336/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0081\n",
      "Epoch 337/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0081\n",
      "Epoch 338/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0081\n",
      "Epoch 339/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0080\n",
      "Epoch 340/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0080\n",
      "Epoch 341/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0080\n",
      "Epoch 342/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0080\n",
      "Epoch 343/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0080\n",
      "Epoch 344/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0080\n",
      "Epoch 345/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0080\n",
      "Epoch 346/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0080\n",
      "Epoch 347/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0079\n",
      "Epoch 348/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0079\n",
      "Epoch 349/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0079\n",
      "Epoch 350/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0079\n",
      "Epoch 351/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0079\n",
      "Epoch 352/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0079\n",
      "Epoch 353/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0079\n",
      "Epoch 354/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0079\n",
      "Epoch 355/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0079\n",
      "Epoch 356/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0078\n",
      "Epoch 357/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0078\n",
      "Epoch 358/500\n",
      "1050/1050 [==============================] - 0s 13us/step - loss: 0.0078\n",
      "Epoch 359/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0078\n",
      "Epoch 360/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0078\n",
      "Epoch 361/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0078\n",
      "Epoch 362/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0078\n",
      "Epoch 363/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0078\n",
      "Epoch 364/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0078\n",
      "Epoch 365/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0077\n",
      "Epoch 366/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0077\n",
      "Epoch 367/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0077\n",
      "Epoch 368/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0077\n",
      "Epoch 369/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0077\n",
      "Epoch 370/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0077\n",
      "Epoch 371/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0077\n",
      "Epoch 372/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0077\n",
      "Epoch 373/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0077\n",
      "Epoch 374/500\n",
      "1050/1050 [==============================] - 0s 20us/step - loss: 0.0076\n",
      "Epoch 375/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0076\n",
      "Epoch 376/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0076\n",
      "Epoch 377/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0076\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0076\n",
      "Epoch 379/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0076\n",
      "Epoch 380/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0076\n",
      "Epoch 381/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0076\n",
      "Epoch 382/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0076\n",
      "Epoch 383/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0075\n",
      "Epoch 384/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0075\n",
      "Epoch 385/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0075\n",
      "Epoch 386/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0075\n",
      "Epoch 387/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0075\n",
      "Epoch 388/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0075\n",
      "Epoch 389/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0075\n",
      "Epoch 390/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0075\n",
      "Epoch 391/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0075\n",
      "Epoch 392/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0075\n",
      "Epoch 393/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0074\n",
      "Epoch 394/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0074\n",
      "Epoch 395/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0074\n",
      "Epoch 396/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0074\n",
      "Epoch 397/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0074\n",
      "Epoch 398/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0074\n",
      "Epoch 399/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0074\n",
      "Epoch 400/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0074\n",
      "Epoch 401/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0074\n",
      "Epoch 402/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0074\n",
      "Epoch 403/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0074\n",
      "Epoch 404/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0073\n",
      "Epoch 405/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0073\n",
      "Epoch 406/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0073\n",
      "Epoch 407/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0073\n",
      "Epoch 408/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0073\n",
      "Epoch 409/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0073\n",
      "Epoch 410/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0073\n",
      "Epoch 411/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0073\n",
      "Epoch 412/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0073\n",
      "Epoch 413/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0073\n",
      "Epoch 414/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0073\n",
      "Epoch 415/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0072\n",
      "Epoch 416/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0072\n",
      "Epoch 417/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0072\n",
      "Epoch 418/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0072\n",
      "Epoch 419/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0072\n",
      "Epoch 420/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0072\n",
      "Epoch 421/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0072\n",
      "Epoch 422/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0072\n",
      "Epoch 423/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0072\n",
      "Epoch 424/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0072\n",
      "Epoch 425/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0072\n",
      "Epoch 426/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0071\n",
      "Epoch 427/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0071\n",
      "Epoch 428/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0071\n",
      "Epoch 429/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0071\n",
      "Epoch 430/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0071\n",
      "Epoch 431/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0071\n",
      "Epoch 432/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0071\n",
      "Epoch 433/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0071\n",
      "Epoch 434/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0071\n",
      "Epoch 435/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0071\n",
      "Epoch 436/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0071\n",
      "Epoch 437/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0071\n",
      "Epoch 438/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0071\n",
      "Epoch 439/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0070\n",
      "Epoch 440/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0070\n",
      "Epoch 441/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0070\n",
      "Epoch 442/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0070\n",
      "Epoch 443/500\n",
      "1050/1050 [==============================] - 0s 21us/step - loss: 0.0070\n",
      "Epoch 444/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0070\n",
      "Epoch 445/500\n",
      "1050/1050 [==============================] - 0s 22us/step - loss: 0.0070\n",
      "Epoch 446/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0070\n",
      "Epoch 447/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0070\n",
      "Epoch 448/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0070\n",
      "Epoch 449/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0070\n",
      "Epoch 450/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0070\n",
      "Epoch 451/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0070\n",
      "Epoch 452/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0069\n",
      "Epoch 453/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0069\n",
      "Epoch 454/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0069\n",
      "Epoch 455/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0069\n",
      "Epoch 456/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0069\n",
      "Epoch 457/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0069\n",
      "Epoch 458/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0069\n",
      "Epoch 459/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0069\n",
      "Epoch 460/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0069\n",
      "Epoch 461/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0069\n",
      "Epoch 462/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0069\n",
      "Epoch 463/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0069\n",
      "Epoch 464/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0069\n",
      "Epoch 465/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0069\n",
      "Epoch 466/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0069\n",
      "Epoch 467/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0068\n",
      "Epoch 468/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0068\n",
      "Epoch 469/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0068\n",
      "Epoch 470/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0068\n",
      "Epoch 471/500\n",
      "1050/1050 [==============================] - 0s 18us/step - loss: 0.0068\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0068\n",
      "Epoch 473/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0068\n",
      "Epoch 474/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0068\n",
      "Epoch 475/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0068\n",
      "Epoch 476/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0068\n",
      "Epoch 477/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0068\n",
      "Epoch 478/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0068\n",
      "Epoch 479/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0068\n",
      "Epoch 480/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0068\n",
      "Epoch 481/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0068\n",
      "Epoch 482/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0068\n",
      "Epoch 483/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 484/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0067\n",
      "Epoch 485/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 486/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0067\n",
      "Epoch 487/500\n",
      "1050/1050 [==============================] - 0s 14us/step - loss: 0.0067\n",
      "Epoch 488/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 489/500\n",
      "1050/1050 [==============================] - 0s 17us/step - loss: 0.0067\n",
      "Epoch 490/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 491/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0067\n",
      "Epoch 492/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0067\n",
      "Epoch 493/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 494/500\n",
      "1050/1050 [==============================] - 0s 19us/step - loss: 0.0067\n",
      "Epoch 495/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 496/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0067\n",
      "Epoch 497/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 498/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n",
      "Epoch 499/500\n",
      "1050/1050 [==============================] - 0s 16us/step - loss: 0.0067\n",
      "Epoch 500/500\n",
      "1050/1050 [==============================] - 0s 15us/step - loss: 0.0067\n"
     ]
    }
   ],
   "source": [
    "train_history = autoencoder.fit(X_, X_, epochs=500, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=encoder.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 10)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dimentions are 10\n",
    "# K Means Clusttring\n",
    "Now we will use kmeans clustering\n",
    "\n",
    "K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n",
    "\n",
    "The objective of K-means is simple: group similar data points together and discover underlying patterns. To achieve this objective, K-means looks for a fixed number (k) of clusters in a dataset\n",
    "\n",
    "\n",
    "## Elbow Method for optimal value of k in KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import cdist \n",
    "distortions = [] \n",
    "inertias = [] \n",
    "mapping1 = {} \n",
    "mapping2 = {} \n",
    "X=X_new\n",
    "for k in range(5,21): \n",
    "    #Building and fitting the model \n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X) \n",
    "    kmeanModel.fit(X)     \n",
    "      \n",
    "    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, \n",
    "                      'euclidean'),axis=1)) / X.shape[0]) \n",
    "    inertias.append(kmeanModel.inertia_) \n",
    "  \n",
    "    mapping1[k] = sum(np.min(cdist(X, kmeanModel.cluster_centers_, \n",
    "                 'euclidean'),axis=1)) / X.shape[0] \n",
    "    mapping2[k] = kmeanModel.inertia_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(range(5,21), distortions, 'bx-') \n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Distortion') \n",
    "plt.title('The Elbow Method using Distortion') \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying kmeans with optimal n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_jobs=-1, n_clusters=20, n_init=20)\n",
    "# pred_auto_train = encoder.predict(X_new)\n",
    "km.fit(X_new)\n",
    "pred = km.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stroing prediction in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ans1.csv\",\"w\") as f:\n",
    "    for i in pred:\n",
    "        print(\"C\"+str(i+1),file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
